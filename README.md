# reflectR
The reflectR package provides a tool for researchers and psychologists to automatically code open-ended responses to the Cognitive Reflection Test, a widely used class of tests in cognitive science and psychology for assessing an individual's propensity to override an incorrect gut response and engage in further reflection to find a correct answer. This package facilitates the standardization of CRT response analysis across large datasets in cognitive psychology, decision-making, and related fields. By automating the coding process, it not only reduces manual effort but also aims to reduce the variability introduced by subjective interpretation of open-ended responses, contributing to a more consistent and reliable analysis. reflectR supports automatic coding and machine scoring for the original English-language version of CRT (Frederick, 2005), as well as for CRT4 and CRT7, 4- and 7-item versions, respectively (Toplak et al., 2014), for the CRTlong version built via Item Response Theory by Primi and colleagues (2016), and for CRT-2 by Thomson & Oppenheimer (2016). 

Note: While reflectR draws inspiration from the principles and scientific literature underlying the different versions of the Cognitive Reflection Test, it has been independently developed and does not hold any affiliation with any of the original authors. 
The development of this package benefited significantly from the kind insight and suggestion provided by Dr. Keela Thomson, whose contribution is gratefully acknowledged.    
